{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d346cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Forecasting - Traffic Volume\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style \n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a276b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 2012-03-12 14:00:00 to 2018-09-06 21:00:00 (15248 hours)\n",
      "Test:  2018-09-06 22:00:00 to 2018-12-09 23:00:00 (720 hours)\n",
      "Train shape: (15248, 70)\n",
      "Test shape: (720, 70)\n"
     ]
    }
   ],
   "source": [
    "# 2. PREPARE DATA (Match LSTM exactly)\n",
    "train = pd.read_csv(\"data_train.csv\", parse_dates=['date_time'], index_col='date_time')\n",
    "test = pd.read_csv(\"data_test.csv\", parse_dates=['date_time'], index_col='date_time')\n",
    "\n",
    "print(f\"\\nTrain: {train.index.min()} to {train.index.max()} ({len(train)} hours)\")\n",
    "print(f\"Test:  {test.index.min()} to {test.index.max()} ({len(test)} hours)\")\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87cadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features for GRU: 14\n",
      "Features: ['traffic_volume', 'temp_c', 'rain_1h', 'snow_1h', 'clouds_all', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'traffic_lag_24', 'traffic_lag_168', 'traffic_rolling_mean_24', 'traffic_rolling_std_24', 'is_holiday']\n",
      "\n",
      "Train data shape: (15248, 14)\n",
      "Test data shape: (720, 14)\n"
     ]
    }
   ],
   "source": [
    "# 3. FEATURE SELECTION (Use same features as LSTM)\n",
    "feature_cols = [\n",
    "    'traffic_volume',    # Target (must be first column)\n",
    "    \n",
    "    # Weather features\n",
    "    'temp_c',\n",
    "    'rain_1h',\n",
    "    'snow_1h',\n",
    "    'clouds_all',\n",
    "    \n",
    "    # Time features\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'dow_sin', 'dow_cos',\n",
    "    \n",
    "    # Lag features\n",
    "    'traffic_lag_24',\n",
    "    'traffic_lag_168',\n",
    "    \n",
    "    # Rolling statistics\n",
    "    'traffic_rolling_mean_24',\n",
    "    'traffic_rolling_std_24',\n",
    "    \n",
    "    # Holiday indicator\n",
    "    'is_holiday'\n",
    "]\n",
    "\n",
    "# Filter to existing columns\n",
    "feature_cols = [c for c in feature_cols if c in train.columns]\n",
    "\n",
    "print(f\"\\nFeatures for GRU: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "\n",
    "# Extract feature matrices (same as LSTM)\n",
    "train_data = train[feature_cols].values\n",
    "test_data = test[feature_cols].values\n",
    "\n",
    "print(f\"\\nTrain data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1cb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scaled shape: (15248, 14)\n",
      "Test scaled shape: (720, 14)\n",
      "Scaled range: [0.000, 1.000]\n",
      "\n",
      "Scaler saved to 'gru_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# 4. SCALING \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train_data)\n",
    "test_scaled = scaler.transform(test_data)\n",
    "\n",
    "print(f\"Train scaled shape: {train_scaled.shape}\")\n",
    "print(f\"Test scaled shape: {test_scaled.shape}\")\n",
    "print(f\"Scaled range: [{train_scaled.min():.3f}, {train_scaled.max():.3f}]\")\n",
    "\n",
    "# Save scaler (same as LSTM)\n",
    "import joblib\n",
    "joblib.dump(scaler, \"gru_scaler.pkl\")\n",
    "print(\"\\nScaler saved to 'gru_scaler.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff1916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features: 14\n",
      "X_train shape: (15224, 24, 14)  (samples, timesteps, features)\n",
      "y_train shape: (15224,)\n",
      "X_test shape:  (696, 24, 14)\n",
      "y_test shape:  (696,)\n"
     ]
    }
   ],
   "source": [
    "# 5. CREATE SEQUENCES \n",
    "def create_sequences(data, window_size=24):\n",
    "    \"\"\"\n",
    "    Create sequences for GRU input (same function as LSTM).\n",
    "    \n",
    "    Args:\n",
    "        data: scaled data array\n",
    "        window_size: lookback period (hours)\n",
    "    \n",
    "    Returns:\n",
    "        X: sequences of shape (samples, window_size, features)\n",
    "        y: targets of shape (samples,)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i, :])  # All features\n",
    "        y.append(data[i, 0])                 # Target (traffic_volume is col 0)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define window size (same as LSTM: 24 hours)\n",
    "WINDOW_SIZE = 24\n",
    "\n",
    "# Create sequences (same as LSTM)\n",
    "X_train, y_train = create_sequences(train_scaled, WINDOW_SIZE)\n",
    "X_test, y_test = create_sequences(test_scaled, WINDOW_SIZE)\n",
    "\n",
    "n_features = X_train.shape[2]\n",
    "print(f\"\\nNumber of features: {n_features}\")\n",
    "print(f\"X_train shape: {X_train.shape}  (samples, timesteps, features)\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape:  {X_test.shape}\")\n",
    "print(f\"y_test shape:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0802e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRU Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m55,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,657</span> (369.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m94,657\u001b[0m (369.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,657</span> (369.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m94,657\u001b[0m (369.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. BUILD GRU MODEL (Structure similar to LSTM)\n",
    "model = Sequential([\n",
    "    # First GRU layer (returns sequences for next GRU)\n",
    "    GRU(128, return_sequences=True, input_shape=(WINDOW_SIZE, n_features)),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Second GRU layer\n",
    "    GRU(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense layers (same as LSTM)\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model (same as LSTM)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"\\nGRU Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653e9403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GRU model...\n",
      "Epoch 1/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - loss: 0.0321 - mae: 0.1335 - val_loss: 0.0084 - val_mae: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - loss: 0.0153 - mae: 0.0924 - val_loss: 0.0050 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - loss: 0.0124 - mae: 0.0824 - val_loss: 0.0042 - val_mae: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 0.0109 - mae: 0.0770 - val_loss: 0.0044 - val_mae: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.0093 - mae: 0.0709 - val_loss: 0.0032 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - loss: 0.0086 - mae: 0.0682 - val_loss: 0.0026 - val_mae: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - loss: 0.0080 - mae: 0.0655 - val_loss: 0.0027 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 32ms/step - loss: 0.0078 - mae: 0.0650 - val_loss: 0.0030 - val_mae: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0632 - val_loss: 0.0027 - val_mae: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - loss: 0.0072 - mae: 0.0619 - val_loss: 0.0024 - val_mae: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - loss: 0.0068 - mae: 0.0600 - val_loss: 0.0021 - val_mae: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.0068 - mae: 0.0600 - val_loss: 0.0024 - val_mae: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - loss: 0.0064 - mae: 0.0583 - val_loss: 0.0020 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 47ms/step - loss: 0.0064 - mae: 0.0580 - val_loss: 0.0023 - val_mae: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - loss: 0.0064 - mae: 0.0580 - val_loss: 0.0031 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m427/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0568\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0573 - val_loss: 0.0022 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0552 - val_loss: 0.0017 - val_mae: 0.0303 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 0.0058 - mae: 0.0547 - val_loss: 0.0018 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - loss: 0.0057 - mae: 0.0543 - val_loss: 0.0018 - val_mae: 0.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - loss: 0.0057 - mae: 0.0543 - val_loss: 0.0021 - val_mae: 0.0344 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - loss: 0.0057 - mae: 0.0543 - val_loss: 0.0022 - val_mae: 0.0362 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m428/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mae: 0.0541\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0056 - mae: 0.0534 - val_loss: 0.0019 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0054 - mae: 0.0523 - val_loss: 0.0017 - val_mae: 0.0301 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0052 - mae: 0.0516 - val_loss: 0.0020 - val_mae: 0.0335 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.0052 - mae: 0.0516 - val_loss: 0.0016 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0052 - mae: 0.0519 - val_loss: 0.0018 - val_mae: 0.0322 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - loss: 0.0051 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0301 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 0.0051 - mae: 0.0514 - val_loss: 0.0017 - val_mae: 0.0306 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - loss: 0.0052 - mae: 0.0515 - val_loss: 0.0016 - val_mae: 0.0288 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m428/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0051 - mae: 0.0509\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - loss: 0.0052 - mae: 0.0512 - val_loss: 0.0016 - val_mae: 0.0299 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 32ms/step - loss: 0.0050 - mae: 0.0505 - val_loss: 0.0017 - val_mae: 0.0306 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.0050 - mae: 0.0503 - val_loss: 0.0016 - val_mae: 0.0301 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - loss: 0.0050 - mae: 0.0505 - val_loss: 0.0016 - val_mae: 0.0291 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0050 - mae: 0.0504 - val_loss: 0.0017 - val_mae: 0.0306 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0048 - mae: 0.0502\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 0.0016 - val_mae: 0.0294 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0503 - val_loss: 0.0016 - val_mae: 0.0293 - learning_rate: 6.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0500 - val_loss: 0.0016 - val_mae: 0.0285 - learning_rate: 6.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 0.0016 - val_mae: 0.0296 - learning_rate: 6.2500e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0502 - val_loss: 0.0016 - val_mae: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m428/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0494\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0492 - val_loss: 0.0017 - val_mae: 0.0304 - learning_rate: 6.2500e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0492 - val_loss: 0.0016 - val_mae: 0.0293 - learning_rate: 3.1250e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0016 - val_mae: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 0.0016 - val_mae: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0498 - val_loss: 0.0015 - val_mae: 0.0284 - learning_rate: 3.1250e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m427/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mae: 0.0490\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0016 - val_mae: 0.0282 - learning_rate: 3.1250e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 0.0016 - val_mae: 0.0294 - learning_rate: 1.5625e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0497 - val_loss: 0.0016 - val_mae: 0.0295 - learning_rate: 1.5625e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 0.0016 - val_mae: 0.0288 - learning_rate: 1.5625e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 0.0016 - val_mae: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0015 - val_mae: 0.0283 - learning_rate: 1.5625e-05\n",
      "Restoring model weights from the end of the best epoch: 50.\n"
     ]
    }
   ],
   "source": [
    "# 7. TRAIN MODEL (Same callbacks and parameters as LSTM)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model (same as LSTM)\n",
    "print(\"\\nTraining GRU model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2267b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions shape:\n",
      "  Train: (15224,)\n",
      "  Test:  (696,)\n"
     ]
    }
   ],
   "source": [
    "# 8. MAKE PREDICTIONS \n",
    "y_train_pred_scaled = model.predict(X_train, verbose=0).flatten()\n",
    "y_test_pred_scaled = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# Use LSTM's exact inverse transform function\n",
    "def inverse_transform_target(scaler, scaled_values, feature_cols):\n",
    "    \"\"\"Inverse transform only the target variable (same as LSTM)\"\"\"\n",
    "    n_features = len(feature_cols)\n",
    "    dummy = np.zeros((len(scaled_values), n_features))\n",
    "    dummy[:, 0] = scaled_values  # traffic_volume is first column\n",
    "    \n",
    "    inverse = scaler.inverse_transform(dummy)\n",
    "    return inverse[:, 0]\n",
    "\n",
    "# Inverse transform \n",
    "y_train_inv = inverse_transform_target(scaler, y_train, feature_cols)\n",
    "y_test_inv = inverse_transform_target(scaler, y_test, feature_cols)\n",
    "y_train_pred_inv = inverse_transform_target(scaler, y_train_pred_scaled, feature_cols)\n",
    "y_test_pred_inv = inverse_transform_target(scaler, y_test_pred_scaled, feature_cols)\n",
    "\n",
    "print(f\"\\nPredictions shape:\")\n",
    "print(f\"  Train: {y_train_pred_inv.shape}\")\n",
    "print(f\"  Test:  {y_test_pred_inv.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1acfe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRU Model Performance:\n",
      "Train → RMSE: 387.37, MAE: 245.82, R²: 0.9616\n",
      "Test  → RMSE: 272.76, MAE: 200.38, R²: 0.9812\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'overfitting_gap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest  → RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mae\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Overfitting check (same as LSTM)ain_r2 - test_r2\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOverfitting check: Train R² - Test R² = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moverfitting_gap\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m overfitting_gap > \u001b[32m0.10\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWarning: Significant overfitting detected\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'overfitting_gap' is not defined"
     ]
    }
   ],
   "source": [
    "# 9. EVALUATE MODEL \n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_inv, y_train_pred_inv))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_inv, y_test_pred_inv))\n",
    "train_mae = mean_absolute_error(y_train_inv, y_train_pred_inv)\n",
    "test_mae = mean_absolute_error(y_test_inv, y_test_pred_inv)\n",
    "train_r2 = r2_score(y_train_inv, y_train_pred_inv)\n",
    "test_r2 = r2_score(y_test_inv, y_test_pred_inv)\n",
    "\n",
    "print(f\"\\nGRU Model Performance:\")\n",
    "print(f\"Train → RMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, R²: {train_r2:.4f}\")\n",
    "print(f\"Test  → RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, R²: {test_r2:.4f}\")\n",
    "\n",
    "# Overfitting check (same as LSTM)ain_r2 - test_r2\n",
    "print(f\"\\nOverfitting check: Train R² - Test R² = {overfitting_gap:.4f}\")\n",
    "if overfitting_gap > 0.10:\n",
    "    print(\"Warning: Significant overfitting detected\")\n",
    "elif overfitting_gap > 0.05:\n",
    "    print(\"Mild overfitting detected\")\n",
    "else:\n",
    "    print(\"Model generalizes well\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. TRAINING HISTORY VISUALIZATION (Same plots as LSTM)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', color='blue', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', color='orange', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('GRU Training vs Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# MAE curve\n",
    "axes[1].plot(history.history['mae'], label='Training MAE', color='blue', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', color='orange', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('GRU Training vs Validation MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. PREDICTIONS VISUALIZATION \n",
    "test_dates = test.index[WINDOW_SIZE:]\n",
    "plot_points = min(500, len(y_test_inv))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(test_dates[:plot_points], y_test_inv[:plot_points], \n",
    "         label='Actual', color='green', linewidth=2, alpha=0.7)\n",
    "plt.plot(test_dates[:plot_points], y_test_pred_inv[:plot_points], \n",
    "         label='GRU Predicted', color='red', linestyle='--', linewidth=1.5)\n",
    "plt.title(f'GRU Forecast vs Actual Traffic Volume (First {plot_points} Test Points)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd66b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. RESIDUAL ANALYSIS \n",
    "residuals = y_test_inv - y_test_pred_inv\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0].plot(test_dates, residuals, color='purple', alpha=0.6)\n",
    "axes[0].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_title('Residuals Over Time (GRU)')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Residual (Actual - Predicted)')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=50, color='teal', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(residuals.mean(), color='red', linestyle='--', \n",
    "                label=f'Mean={residuals.mean():.2f}')\n",
    "axes[1].set_title('Residual Distribution (GRU)')\n",
    "axes[1].set_xlabel('Residual')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[2].scatter(y_test_pred_inv, residuals, alpha=0.3, color='orange', s=10)\n",
    "axes[2].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[2].set_title('Residuals vs Predicted Values (GRU)')\n",
    "axes[2].set_xlabel('Predicted Traffic Volume')\n",
    "axes[2].set_ylabel('Residual')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual statistics \n",
    "print(\"\\nResidual Statistics:\")\n",
    "print(pd.Series(residuals).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5043ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. NAIVE BASELINE COMPARISON \n",
    "if 'traffic_lag_168' in test.columns:\n",
    "    naive_pred = test['traffic_lag_168'].values[WINDOW_SIZE:]\n",
    "    valid_idx = ~np.isnan(naive_pred)\n",
    "    naive_pred_clean = naive_pred[valid_idx]\n",
    "    y_test_clean = y_test_inv[valid_idx]\n",
    "    \n",
    "    naive_rmse = np.sqrt(mean_squared_error(y_test_clean, naive_pred_clean))\n",
    "    naive_mae = mean_absolute_error(y_test_clean, naive_pred_clean)\n",
    "    naive_r2 = r2_score(y_test_clean, naive_pred_clean)\n",
    "    \n",
    "    print(f\"\\nNaive Seasonal Baseline (lag 168h):\")\n",
    "    print(f\"  RMSE: {naive_rmse:.2f}\")\n",
    "    print(f\"  MAE:  {naive_mae:.2f}\")\n",
    "    print(f\"  R²:   {naive_r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nGRU Improvement over Naive:\")\n",
    "    print(f\"  RMSE reduction: {((naive_rmse - test_rmse) / naive_rmse * 100):.1f}%\")\n",
    "    print(f\"  MAE reduction: {((naive_mae - test_mae) / naive_mae * 100):.1f}%\")\n",
    "else:\n",
    "    print(\"\\nWarning: traffic_lag_168 not available for naive baseline\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d817bb",
   "metadata": {},
   "source": [
    "- important concept in time series forecasting\n",
    "- The naive baseline establishes the **minimum performance threshold** any useful model must exceed. \n",
    "- It answers the fundamental question: **Does my complex model provide meaningful improvement over simple, intuitive approaches?**\n",
    "so as to question whether the additional complexity is justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. SAVE MODEL\n",
    "model.save('gru_traffic_model.h5')\n",
    "print(\"\\nGRU Model saved to 'gru_traffic_model.h5'\")\n",
    "\n",
    "# Save metrics for comparison (same format as LSTM)\n",
    "gru_results = {\n",
    "    'model': 'GRU',\n",
    "    'train_rmse': train_rmse,\n",
    "    'test_rmse': test_rmse,\n",
    "    'train_mae': train_mae,\n",
    "    'test_mae': test_mae,\n",
    "    'train_r2': train_r2,\n",
    "    'test_r2': test_r2,\n",
    "    'window_size': WINDOW_SIZE,\n",
    "    'n_features': n_features\n",
    "}\n",
    "\n",
    "# Save to CSV \n",
    "results_df = pd.DataFrame([gru_results])\n",
    "results_df.to_csv(\"gru_results.csv\", index=False)\n",
    "print(\"GRU Results saved to 'gru_results.csv'\")\n",
    "\n",
    "print(\"\\nGRU workflow completed - fully aligned with LSTM structure!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
